server:
  port: 8082

spring:
  application:
    name: spring-ai-chat-llm

  ai:
    openai:
      base-url: https://api.groq.com/openai
      api-key: ${GROQ_API_KEY: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}
      chat:
        options:
          model: llama-3.1-8b-instant
#          temperature: 0.7          # randomness (0.0 = deterministic, 1.0 = creative)
#          max-tokens: 512            # maximum length of model output
#          top-p: 1.0                 # nucleus sampling parameter
#          presence-penalty: 0.0      # discourages repeating topics
#          frequency-penalty: 0.0     # discourages repeating exact phrases
#          stop: # optional stop sequences
#            - "Human:"
#            - "AI:"
#          seed: 42                   # optional, ensures reproducible results
#          user: jareer               # optional identifier for request tracking
logging:
  level:
    org.springframework.ai: INFO
